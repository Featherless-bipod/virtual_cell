{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e8bdde",
   "metadata": {},
   "source": [
    "### VirtCell Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf83d12-912c-4440-bbde-57b447beb309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "511d78bd-d339-4749-aeac-1dda13a71ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: (100, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target_gene</th><th>n_cells</th><th>median_umi_per_cell</th></tr><tr><td>str</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;GRB10&quot;</td><td>4074</td><td>54815.0</td></tr><tr><td>&quot;STXBP1&quot;</td><td>3751</td><td>55077.0</td></tr><tr><td>&quot;PLAGL2&quot;</td><td>3642</td><td>54355.0</td></tr><tr><td>&quot;MED15&quot;</td><td>3637</td><td>50285.0</td></tr><tr><td>&quot;SOX4&quot;</td><td>3343</td><td>57576.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────┬─────────┬─────────────────────┐\n",
       "│ target_gene ┆ n_cells ┆ median_umi_per_cell │\n",
       "│ ---         ┆ ---     ┆ ---                 │\n",
       "│ str         ┆ i64     ┆ f64                 │\n",
       "╞═════════════╪═════════╪═════════════════════╡\n",
       "│ GRB10       ┆ 4074    ┆ 54815.0             │\n",
       "│ STXBP1      ┆ 3751    ┆ 55077.0             │\n",
       "│ PLAGL2      ┆ 3642    ┆ 54355.0             │\n",
       "│ MED15       ┆ 3637    ┆ 50285.0             │\n",
       "│ SOX4        ┆ 3343    ┆ 57576.0             │\n",
       "└─────────────┴─────────┴─────────────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define our path\n",
    "pert_counts_path = \"vcc_data/pert_counts_Test.csv\"\n",
    "\n",
    "# Read in the csv\n",
    "pert_counts = pl.read_csv(pert_counts_path)\n",
    "\n",
    "# Show the dimensions\n",
    "print(f\"Dimensions: {pert_counts.shape}\")\n",
    "pert_counts.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5cb7d9-d96d-46e6-82a8-bc2ccb047592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SAMD11', 'NOC2L', 'KLHL17', ..., 'MT-ND5', 'MT-ND6', 'MT-CYB'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_names_path = \"vcc_data/gene_names.csv\"\n",
    "\n",
    "# Read this in and immediately convert to array\n",
    "gene_names = pl.read_csv(gene_names_path, has_header=False).to_numpy().flatten()\n",
    "\n",
    "gene_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb1b9ed",
   "metadata": {},
   "source": [
    "### Prepping Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b954d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pyensembl\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da645a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.updatedmodel as m\n",
    "import src.data_cleaning as dc\n",
    "import src.position_encoding as pos\n",
    "import src.pathway_encoding as path\n",
    "import src.updatetraining as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5afce22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /hpc/home/zy231/.cache/pyensembl/GRCh38/ensembl109/Homo_sapiens.GRCh38.cdna.all.fa.gz.pickle\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /hpc/home/zy231/.cache/pyensembl/GRCh38/ensembl109/Homo_sapiens.GRCh38.ncrna.fa.gz.pickle\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /hpc/home/zy231/.cache/pyensembl/GRCh38/ensembl109/Homo_sapiens.GRCh38.pep.all.fa.gz.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing positional indices using pyensembl ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching gene positions: 100%|██████████| 18080/18080 [02:22<00:00, 126.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUCCESS: Generated positional tensors with shapes:\n",
      "Chromosome Indices (chr_idx): torch.Size([18080])\n",
      "Normalized Locus (locus_norm): torch.Size([18080, 1])\n",
      "Locus Fourier Features (locus_fourier): torch.Size([18080, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "adata = sc.read_h5ad('vcc_data/adata_Training.h5ad')\n",
    "#adata.obs['perturbation_idx'] = np.random.randint(0, CONFIG[\"n_perturbations\"], size=adata.n_obs)\n",
    "#gene_names = pd.read_csv('vcc_data/gene_names.csv', header = None)\n",
    "#gene_names = gene_names.iloc[:, 0].tolist()\n",
    "\n",
    "CONFIG = {\n",
    "    \"n_genes\": len(gene_names), #total number of expression genes needed to predict\n",
    "    \"n_perturbations\": len(adata.obs['target_gene'].unique().tolist()), #number of unique perturbations\n",
    "    \"n_chromosomes\": 25, #chromosome number 23+X+Y\n",
    "\n",
    "    \"perturbation_dim\": 256,      # Condition embedding\n",
    "    \"chrom_embedding_dim\": 16,     # Learned in-model for chromosome identity\n",
    "    \"locus_fourier_features\": 8,   # Number of Fourier frequency pairs (2*F)\n",
    "    \"pathway_dim\": 50,             # From pre-trained Autoencoder(based on hallmark MSigDB)\n",
    "    \"gene_identity_dim\": 189,       # Main learnable gene embedding\n",
    "\n",
    "    # Backbone dims\n",
    "    \"d_model\": 512,                # Mamba hidden size\n",
    "    \"mamba_layers\": 4,\n",
    "    \"n_heads\": 8,\n",
    "    \"n_layers\": 4,\n",
    "\n",
    "    # Head\n",
    "    \"prediction_head\": \"probabilistic\", # \"linear\" | \"probabilistic\"\n",
    "\n",
    "    # Training\n",
    "    \"batch_size\": 4,\n",
    "    \"learning_rate\": 5e-5, # Lowered LR for AdamW stability\n",
    "    \"epochs\": 50,\n",
    "}\n",
    "\n",
    "POS_DIM = CONFIG[\"chrom_embedding_dim\"] + CONFIG[\"chrom_embedding_dim\"]\n",
    "GENE_FEAT_DIM = CONFIG[\"gene_identity_dim\"] + CONFIG[\"pathway_dim\"] + POS_DIM\n",
    "\n",
    "ensembl_data = pyensembl.EnsemblRelease(109)\n",
    "ensembl_data.download()\n",
    "ensembl_data.index()\n",
    "\n",
    "unique_genes = adata.var.index.tolist()\n",
    "perturbation_to_idx_map = {name: i for i, name in enumerate(unique_genes)}\n",
    "adata.obs['perturbation_idx'] = adata.obs['target_gene'].map(perturbation_to_idx_map)\n",
    "adata.obs['perturbation_idx'] = adata.obs['perturbation_idx'].fillna(CONFIG['n_genes']).astype(int)\n",
    "control_adata = dc.get_control_data(adata)\n",
    "chr_idx, locus_norm, locus_fourier = pos.precompute_positional_indices(ensembl_data, gene_names, CONFIG)\n",
    "\n",
    "pathway_feats = np.load('pathway_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b3b310f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset using log-normalized data from adata.X for linear head.\n"
     ]
    }
   ],
   "source": [
    "dataset = m.PerturbationDataset(adata,CONFIG)\n",
    "test_loader = DataLoader(dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "543f8905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Creating a new, untrained model instance...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TranscriptomePredictor(\n",
       "  (gene_id_emb): Embedding(18080, 189)\n",
       "  (chr_emb): Embedding(25, 16)\n",
       "  (locus_mlp): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "  )\n",
       "  (cond_proj): Linear(in_features=271, out_features=271, bias=True)\n",
       "  (input_proj): Linear(in_features=271, out_features=512, bias=True)\n",
       "  (input_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (backbone): BiMamba(\n",
       "    (mamba_fwd): Mamba2(\n",
       "      (in_proj): Linear(in_features=512, out_features=2320, bias=False)\n",
       "      (conv1d): Conv1d(1280, 1280, kernel_size=(4,), stride=(1,), padding=(3,), groups=1280)\n",
       "      (act): SiLU()\n",
       "      (norm): RMSNorm()\n",
       "      (out_proj): Linear(in_features=1024, out_features=512, bias=False)\n",
       "    )\n",
       "    (mamba_bwd): Mamba2(\n",
       "      (in_proj): Linear(in_features=512, out_features=2320, bias=False)\n",
       "      (conv1d): Conv1d(1280, 1280, kernel_size=(4,), stride=(1,), padding=(3,), groups=1280)\n",
       "      (act): SiLU()\n",
       "      (norm): RMSNorm()\n",
       "      (out_proj): Linear(in_features=1024, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (output_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "print(\"Creating a new, untrained model instance...\")\n",
    "model = m.TranscriptomePredictor(CONFIG, GENE_FEAT_DIM, pathway_feats, chr_idx, locus_fourier)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db4f5179-40ad-4bcc-bc24-5e694c19939b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved weights from update_weights(2).pth...\n",
      "\n",
      "--- ✅ Model loaded successfully! ---\n"
     ]
    }
   ],
   "source": [
    "# --- 3. LOAD THE SAVED WEIGHTS (THE .pth FILE) ---\n",
    "model_path = \"update_weights(2).pth\"\n",
    "print(f\"Loading saved weights from {model_path}...\")\n",
    "\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"\\n--- ✅ Model loaded successfully! ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e66a0a",
   "metadata": {},
   "source": [
    "### Get Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9434c68a-5f7d-4f45-a04b-c53c4153a33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277e0bdba8e041e9be246eea2fc40dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating predictions:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 74.37 GiB. GPU 0 has a total capacity of 23.55 GiB of which 23.13 GiB is free. Including non-PyTorch memory, this process has 420.00 MiB memory in use. Of the allocated memory 143.45 MiB is allocated by PyTorch, and 24.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m         predictions_batch \u001b[38;5;241m=\u001b[39m model(input_tensor)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m         mean_log, _ \u001b[38;5;241m=\u001b[39m model(input_tensor)\n\u001b[1;32m     45\u001b[0m         predictions_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(mean_log) \n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Move the small result to the CPU, freeing VRAM\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/work/zy231/virtual_cell/src/updatedmodel.py:85\u001b[0m, in \u001b[0;36mTranscriptomePredictor.forward\u001b[0;34m(self, perturbation_idx)\u001b[0m\n\u001b[1;32m     83\u001b[0m cond_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_features[perturbation_idx]\n\u001b[1;32m     84\u001b[0m cond_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcond_proj(cond_vec)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([cond_token, gene_matrix], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     86\u001b[0m seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_proj(seq) \u001b[38;5;66;03m# Shape is (B, 18081, 512)\u001b[39;00m\n\u001b[1;32m     87\u001b[0m seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_norm(seq)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 74.37 GiB. GPU 0 has a total capacity of 23.55 GiB of which 23.13 GiB is free. Including non-PyTorch memory, this process has 420.00 MiB memory in use. Of the allocated memory 143.45 MiB is allocated by PyTorch, and 24.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "import gc\n",
    "\n",
    "# --- 1. Define a manageable batch size ---\n",
    "# This is the \"fix\". We will only process this many cells at a time.\n",
    "EVAL_BATCH_SIZE = 4096 \n",
    "\n",
    "all_predictions = []\n",
    "all_target_names = []\n",
    "\n",
    "# --- 2. Setup Model ---\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(pert_counts.rows(named=True), total=len(pert_counts), desc=\"Generating predictions\")\n",
    "    \n",
    "    # --- This loop is fine ---\n",
    "    for row in pbar:\n",
    "        pert_name = row['target_gene']\n",
    "        num_cells = row['n_cells']\n",
    "        pert_idx = perturbation_to_idx_map[pert_name]\n",
    "        \n",
    "        # -----------------------------------------------------------------\n",
    "        # --- FIX: Inner loop to process in small batches ---\n",
    "        # This new loop breaks the large 'num_cells' into small chunks\n",
    "        # -----------------------------------------------------------------\n",
    "        for start_idx in range(0, num_cells, EVAL_BATCH_SIZE):\n",
    "            \n",
    "            # Calculate the size of this specific (and small) batch\n",
    "            end_idx = min(start_idx + EVAL_BATCH_SIZE, num_cells)\n",
    "            current_batch_size = end_idx - start_idx\n",
    "            \n",
    "            # Create a *small* input tensor (e.g., [4096])\n",
    "            input_tensor = torch.tensor([pert_idx] * current_batch_size, dtype=torch.long).to(device)\n",
    "            \n",
    "            # Run the model *only* on the small batch\n",
    "            # This will NOT try to allocate 74.37 GiB\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                if CONFIG[\"prediction_head\"] == \"linear\":\n",
    "                    predictions_batch = model(input_tensor)\n",
    "                else:\n",
    "                    mean_log, _ = model(input_tensor)\n",
    "                    predictions_batch = torch.exp(mean_log) \n",
    "\n",
    "            # Move the small result to the CPU, freeing VRAM\n",
    "            all_predictions.append(predictions_batch.cpu().numpy().squeeze(-1))\n",
    "            all_target_names.extend([pert_name] * current_batch_size)\n",
    "            \n",
    "        # --- End of the new inner loop ---\n",
    "\n",
    "\n",
    "# --- 5. Create the final AnnData object on the CPU ---\n",
    "print(\"\\nCreating final AnnData submission file...\")\n",
    "\n",
    "final_X = np.concatenate(all_predictions, axis=0)\n",
    "final_X = final_X.astype(np.float32) \n",
    "\n",
    "final_obs = pd.DataFrame({'target_gene': all_target_names})\n",
    "final_obs.index = final_obs.index.astype(str) \n",
    "\n",
    "final_var = pd.DataFrame(index=gene_names)\n",
    "final_var.index.name = \"gene_name\" \n",
    "\n",
    "submission_adata = ad.AnnData(X=final_X, obs=final_obs, var=final_var)\n",
    "\n",
    "# 6. Save the file\n",
    "submission_adata.write_h5ad(\"my_submission.h5ad\", compression=\"gzip\")\n",
    "\n",
    "print(f\"\\n✅ Submission file created: 'my_submission.h5ad'\")\n",
    "print(submission_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7f55e69-ec34-48ff-9318-008b7eb64f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c297bb582d4bd79487e59623d20bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating predictions:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'mapping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m num_cells \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_cells\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Find the correct integer ID for your model\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m pert_idx \u001b[38;5;241m=\u001b[39m mapping[pert_name]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create a batch of inputs (e.g., 200 copies of ID 1)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([pert_idx] \u001b[38;5;241m*\u001b[39m num_cells, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mapping' is not defined"
     ]
    }
   ],
   "source": [
    "pert_counts_path = \"vcc_data/pert_counts_Test.csv\"\n",
    "pert_counts = pl.read_csv(pert_counts_path)\n",
    "gene_names_path = \"vcc_data/gene_names.csv\"\n",
    "gene_names = pl.read_csv(gene_names_path, has_header=False).to_numpy().flatten()\n",
    "\n",
    "\n",
    "all_predictions = []\n",
    "all_target_names = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(pert_counts.rows(named=True), total=len(pert_counts), desc=\"Generating predictions\")\n",
    "    \n",
    "    for row in pbar:\n",
    "        pert_name = row['target_gene']\n",
    "        num_cells = row['n_cells']\n",
    "        \n",
    "        # Find the correct integer ID for your model\n",
    "        pert_idx = mapping[pert_name]\n",
    "        \n",
    "        # Create a batch of inputs (e.g., 200 copies of ID 1)\n",
    "        input_tensor = torch.tensor([pert_idx] * num_cells, dtype=torch.long).to(device)\n",
    "        \n",
    "\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            if CONFIG[\"prediction_head\"] == \"linear\":\n",
    "                predictions = model(input_tensor)\n",
    "            else:\n",
    "                # For submission, we just want the \"best guess\" (the mean)\n",
    "                mean_log, _ = model(input_tensor)\n",
    "                predictions = torch.exp(mean_log) # Get mean from log-mean\n",
    "\n",
    "        all_predictions.append(predictions.cpu().numpy().squeeze())\n",
    "        all_target_names.extend([pert_name] * num_cells)\n",
    "\n",
    "# --- 5. Create the final AnnData object ---\n",
    "\n",
    "print(\"\\nCreating final AnnData submission file...\")\n",
    "\n",
    "# Concatenate all predicted expression matrices\n",
    "final_X = np.concatenate(all_predictions, axis=0)\n",
    "final_X = final_X.astype(np.float32) # Rule 5: Must be float32\n",
    "\n",
    "# Create the .obs dataframe (this is the correct structure)\n",
    "final_obs = pd.DataFrame({'target_gene': all_target_names})\n",
    "final_obs.index = final_obs.index.astype(str) # Make index strings\n",
    "\n",
    "# Create the .var dataframe (must match training gene list)\n",
    "final_var = pd.DataFrame(index=gene_names)\n",
    "final_var.index.name = \"gene_name\" # Good practice\n",
    "\n",
    "# Build the submission anndata\n",
    "submission_adata = ad.AnnData(X=final_X, obs=final_obs, var=final_var)\n",
    "\n",
    "# 9. Save the file\n",
    "submission_adata.write_h5ad(\"my_submission.h5ad\", compression=\"gzip\")\n",
    "\n",
    "print(f\"\\n✅ Submission file created: 'my_submission.h5ad'\")\n",
    "print(submission_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db83492-9599-4170-9a5c-c1c64d30ce77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell_env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
