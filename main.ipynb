{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756898ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from IPython.display import clear_output, display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pyensembl\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5132db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.updatedmodel as m\n",
    "import src.data_cleaning as dc\n",
    "import src.position_encoding as pos\n",
    "import src.pathway_encoding as path\n",
    "import src.updatetraining as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18698ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_data = pyensembl.EnsemblRelease(109)\n",
    "ensembl_data.download()\n",
    "ensembl_data.index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f002e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad('vcc_data/adata_Training.h5ad')\n",
    "#adata.obs['perturbation_idx'] = np.random.randint(0, CONFIG[\"n_perturbations\"], size=adata.n_obs)\n",
    "gene_names = pd.read_csv('vcc_data/gene_names.csv', header = None)\n",
    "gene_names = gene_names.iloc[:, 0].tolist()\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    \"n_genes\": len(gene_names), #total number of expression genes needed to predict\n",
    "    \"n_perturbations\": len(adata.obs['target_gene'].unique().tolist()), #number of unique perturbations\n",
    "    \"n_chromosomes\": 25, #chromosome number 23+X+Y\n",
    "\n",
    "    \"perturbation_dim\": 256,      # Condition embedding\n",
    "    \"chrom_embedding_dim\": 16,     # Learned in-model for chromosome identity\n",
    "    \"locus_fourier_features\": 8,   # Number of Fourier frequency pairs (2*F)\n",
    "    \"pathway_dim\": 50,             # From pre-trained Autoencoder(based on hallmark MSigDB)\n",
    "    \"gene_identity_dim\": 189,       # Main learnable gene embedding\n",
    "\n",
    "    # Backbone dims\n",
    "    \"d_model\": 512,                # Mamba hidden size\n",
    "    \"mamba_layers\": 4,\n",
    "    \"n_heads\": 8,\n",
    "    \"n_layers\": 4,\n",
    "\n",
    "    # Head\n",
    "    \"prediction_head\": \"probabilistic\", # \"linear\" | \"probabilistic\"\n",
    "\n",
    "    # Training\n",
    "    \"batch_size\": 16,\n",
    "    \"learning_rate\": 5e-5, # Lowered LR for AdamW stability\n",
    "    \"epochs\": 100,\n",
    "}\n",
    "\n",
    "# Derived dimensions for clarity\n",
    "# Positional encoding dim = chromosome embedding + MLP output from Fourier features\n",
    "POS_DIM = CONFIG[\"chrom_embedding_dim\"] + CONFIG[\"chrom_embedding_dim\"]\n",
    "GENE_FEAT_DIM = CONFIG[\"gene_identity_dim\"] + CONFIG[\"pathway_dim\"] + POS_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67219948",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genes = adata.var.index.tolist()\n",
    "perturbation_to_idx_map = {name: i for i, name in enumerate(unique_genes)}\n",
    "adata.obs['perturbation_idx'] = adata.obs['target_gene'].map(perturbation_to_idx_map)\n",
    "adata.obs['perturbation_idx'] = adata.obs['perturbation_idx'].fillna(CONFIG['n_genes']).astype(int)\n",
    "control_adata = dc.get_control_data(adata)\n",
    "chr_idx, locus_norm, locus_fourier = pos.precompute_positional_indices(ensembl_data, gene_names, CONFIG)\n",
    "pathway_feats = np.load('pathway_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be122a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "model = m.TranscriptomePredictor(CONFIG, GENE_FEAT_DIM, pathway_feats, chr_idx, locus_fourier)\n",
    "model.to(device)\n",
    "\n",
    "dataset = m.PerturbationDataset(adata, CONFIG) # Pass CONFIG to the dataset constructor\n",
    "train_loader = DataLoader(dataset, batch_size=CONFIG[\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f15f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Checking every dataset entry for NaNs ---\")\n",
    "\n",
    "nan_found_at_index = -1\n",
    "total_samples = len(dataset)\n",
    "\n",
    "# Use tqdm for a progress bar\n",
    "for i in tqdm(range(total_samples), desc=\"Scanning dataset\"):\n",
    "    sample = dataset[i]\n",
    "    target_expr = sample[\"target_expression\"]\n",
    "    \n",
    "    # Check if this tensor has any NaN values\n",
    "    if torch.isnan(target_expr).any():\n",
    "        nan_found_at_index = i\n",
    "        break # Stop as soon as we find one\n",
    "\n",
    "# --- Report the result ---\n",
    "if nan_found_at_index != -1:\n",
    "    print(\"\\n!!!!! CRITICAL: NaN DETECTED !!!!!\")\n",
    "    print(f\"A NaN value was found in the 'target_expression' for sample index: {nan_found_at_index}\")\n",
    "    print(\"This is the likely cause of your CUDA error.\")\n",
    "else:\n",
    "    print(\"\\nOK: Scanned all {total_samples} samples. The dataset is 100% clean of NaNs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a35312",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = train.train_model(model, train_loader, CONFIG,device)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
